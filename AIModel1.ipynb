{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNq++IOgu2iLEUfrepKBpgE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PzdWmWqCwPvD","executionInfo":{"status":"ok","timestamp":1699360220901,"user_tz":-330,"elapsed":4542,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCk8DMwDwxoQ","executionInfo":{"status":"ok","timestamp":1699360258277,"user_tz":-330,"elapsed":27669,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"15d8e04f-72cb-413d-f145-5817819a0b3b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install rarfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkofquGNwxp-","executionInfo":{"status":"ok","timestamp":1699360269549,"user_tz":-330,"elapsed":7713,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"0753874f-e7ed-4cc6-8345-3474b46c3fe7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rarfile\n","  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n","Installing collected packages: rarfile\n","Successfully installed rarfile-4.1\n"]}]},{"cell_type":"code","source":["from rarfile import RarFile\n","\n","# Replace 'your_file.rar' with the actual filename\n","rar_file_path = '/content/drive/MyDrive/Sonoimages.rar'\n","\n","# Specify the directory where you want to extract the files\n","extracted_dir1= '/content/extracted_files1'\n","\n","# Create the directory if it doesn't exist\n","import os\n","if not os.path.exists(extracted_dir1):\n","    os.makedirs(extracted_dir1)\n","\n","# Open the .rar file\n","with RarFile(rar_file_path, 'r') as rar:\n","    rar.extractall(extracted_dir1)\n","\n","# List the extracted files\n","extracted_files1 = os.listdir(extracted_dir1)\n","print(\"Extracted files:\")\n","for file in extracted_files1:\n","    print(file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTB0pWe5wxsg","executionInfo":{"status":"ok","timestamp":1699360476890,"user_tz":-330,"elapsed":1238,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"ecffacd8-c929-4e5e-ccb2-88ea3e291a43"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted files:\n","Sonoimages\n"]}]},{"cell_type":"code","source":["from PIL import Image, ImageDraw, ImageOps, ImageFilter\n","import os\n","\n","# Function to annotate an image\n","def annotate_image(image_path, annotations):\n","    image = Image.open(image_path)\n","    draw = ImageDraw.Draw(image)\n","\n","    for annotation in annotations:\n","        # Assuming annotation is a dictionary with keys for label and coordinates.\n","        label = annotation['label']\n","        coordinates = annotation['coordinates']\n","        draw.rectangle(coordinates, outline='red')\n","        draw.text((coordinates[0], coordinates[1] - 10), label, fill='red')\n","\n","    annotated_image_path = 'annotated_' + os.path.basename(image_path)\n","    image.save(annotated_image_path)\n","    return annotated_image_path\n","\n","# Function to preprocess and standardize an image\n","def preprocess_image(image_path):\n","    image = Image.open(image_path)\n","\n","    # Resize the image to a specific size (e.g., 224x224)\n","    target_size = (224, 224)\n","    image = image.resize(target_size, Image.ANTIALIAS)\n","\n","    # Apply normalization (convert to a 0-1 range)\n","    image = ImageOps.autocontrast(image)\n","\n","    # Apply noise reduction (e.g., Gaussian blur)\n","    image = image.filter(ImageFilter.GaussianBlur(radius=2))\n","\n","    preprocessed_image_path = 'preprocessed_' + os.path.basename(image_path)\n","    image.save(preprocessed_image_path)\n","    return preprocessed_image_path\n","\n","# Specify the directory path where the sonography images are located\n","directory_path = '/content/extracted_files1'\n","\n","# Iterate through your dataset\n","for folder_name in os.listdir(directory_path):\n","    folder_path = os.path.join(directory_path, folder_name)\n","    if os.path.isdir(folder_path):\n","        for image_name in os.listdir(folder_path):\n","            image_path = os.path.join(folder_path, image_name)\n","            annotations = []  # Your annotations for the image (e.g., label and coordinates)\n","\n","            # Define and populate annotations as needed\n","            annotations = [\n","                {\n","                    'label': 'Annotation1',\n","                    'coordinates': (10, 10, 100, 100)  # (left, top, right, bottom)\n","                },\n","                # Add more annotations as needed\n","            ]\n","\n","            # Annotate the image\n","            annotated_image_path = annotate_image(image_path, annotations)\n","            print(f'Annotated image saved as {annotated_image_path}')\n","\n","            # Preprocess the annotated image\n","            preprocessed_image_path = preprocess_image(annotated_image_path)\n","            print(f'Preprocessed image saved as {preprocessed_image_path}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKkcR-tHwxux","executionInfo":{"status":"ok","timestamp":1699360575832,"user_tz":-330,"elapsed":437,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"a5e2f7d8-98fb-429d-d5cb-2725c8dfbded"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Annotated image saved as annotated_im4.jpg\n","Preprocessed image saved as preprocessed_annotated_im4.jpg\n","Annotated image saved as annotated_im1.jpg\n","Preprocessed image saved as preprocessed_annotated_im1.jpg\n","Annotated image saved as annotated_im3.jpg\n","Preprocessed image saved as preprocessed_annotated_im3.jpg\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-10f00cc73663>:26: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  image = image.resize(target_size, Image.ANTIALIAS)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Directory paths for your annotated and preprocessed images\n","annotated_images_dir = '/content/extracted_files1'\n","preprocessed_images_dir = '/content/extracted_files1'\n","\n","# Parameters for the CNN model\n","input_shape = (224, 224, 3)  # Input image size\n","num_classes = 2  # Number of classes (adjust as needed)\n","batch_size = 32\n","epochs = 10\n","\n","# Data augmentation and normalization\n","data_generator = ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.2\n",")\n","\n","# Split the data into training and validation sets\n","train_generator = data_generator.flow_from_directory(\n","    preprocessed_images_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","validation_generator = data_generator.flow_from_directory(\n","    preprocessed_images_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","# Build a CNN model\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dense(num_classes, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(train_generator, validation_data=validation_generator, epochs=epochs)\n","\n","# Save the trained model\n","model.save('image_classification_model.keras')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLUOXXDMwxwQ","executionInfo":{"status":"ok","timestamp":1699361378939,"user_tz":-330,"elapsed":9594,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"88f318e8-4225-42c8-f8c7-ec47e9bb53ab"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3 images belonging to 1 classes.\n","Found 0 images belonging to 1 classes.\n","Epoch 1/10\n","1/1 [==============================] - 2s 2s/step - loss: 1.3880 - accuracy: 1.0000\n","Epoch 2/10\n","1/1 [==============================] - 1s 517ms/step - loss: 1.6822 - accuracy: 0.0000e+00\n","Epoch 3/10\n","1/1 [==============================] - 0s 466ms/step - loss: 7.2082 - accuracy: 1.0000\n","Epoch 4/10\n","1/1 [==============================] - 0s 489ms/step - loss: 1.9612 - accuracy: 1.0000\n","Epoch 5/10\n","1/1 [==============================] - 1s 640ms/step - loss: 16.4998 - accuracy: 0.0000e+00\n","Epoch 6/10\n","1/1 [==============================] - 1s 517ms/step - loss: 17.2934 - accuracy: 0.0000e+00\n","Epoch 7/10\n","1/1 [==============================] - 0s 480ms/step - loss: 8.4723 - accuracy: 1.0000\n","Epoch 8/10\n","1/1 [==============================] - 1s 526ms/step - loss: 7.2072 - accuracy: 1.0000\n","Epoch 9/10\n","1/1 [==============================] - 1s 647ms/step - loss: 40.8194 - accuracy: 0.0000e+00\n","Epoch 10/10\n","1/1 [==============================] - 1s 551ms/step - loss: 39.4871 - accuracy: 0.0000e+00\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","\n","# Load the saved model\n","loaded_model = keras.models.load_model('image_classification_model.keras')"],"metadata":{"id":"dQnMLwIn4UTs","executionInfo":{"status":"ok","timestamp":1699362250964,"user_tz":-330,"elapsed":4252,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","\n","# Load the image and preprocess it to match the input size and format expected by the model\n","new_image = Image.open('/content/newIm.jpg')\n","new_image = new_image.resize((224, 224))  # Resize to match the model's input size\n","new_image = np.array(new_image)  # Convert to a NumPy array\n","new_image = new_image / 255.0  # Normalize the image (assuming pixel values are in the range [0, 255])\n","\n","# Make predictions on the preprocessed image\n","predictions = loaded_model.predict(np.expand_dims(new_image, axis=0))\n","\n","# Assuming binary classification, set a threshold for risk detection\n","threshold = 0.5  # You can adjust this threshold as needed\n","\n","# Classify as \"risk\" if the probability is above the threshold\n","is_pregnancy_risk = predictions > threshold\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fn_k27q95ldl","executionInfo":{"status":"ok","timestamp":1699362975129,"user_tz":-330,"elapsed":864,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"2945cc2b-3997-4132-8a4b-39f75cfc74c7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 53ms/step\n"]}]},{"cell_type":"code","source":["label = \"Pregnancy Risk\" if is_pregnancy_risk.any() else \"No Pregnancy Risk\"\n","\n","# Interpret the results and provide recommendations\n","if is_pregnancy_risk.any():\n","    # If the model predicts pregnancy risk\n","    print(f\"The model predicts {label}. Take appropriate actions.\")\n","    # You can provide specific recommendations for healthcare professionals or patients.\n","else:\n","    # If the model predicts no pregnancy risk\n","    print(f\"The model predicts {label}. No immediate action required.\")\n","\n","# You can also access the model's confidence in its prediction\n","confidence = predictions[0][0]  # Assuming the model output for \"risk\" is at index 0\n","print(f\"Confidence: {confidence:.2%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcEmBngq6Uf7","executionInfo":{"status":"ok","timestamp":1699363173534,"user_tz":-330,"elapsed":552,"user":{"displayName":"Pooja Kachate","userId":"18175058840007892574"}},"outputId":"4a85e38a-f1b8-4d28-b507-229f81ca3dde"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["The model predicts Pregnancy Risk. Take appropriate actions.\n","Confidence: 100.00%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5j3NLsw46Uhw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nbg4ugcT6Uk9"},"execution_count":null,"outputs":[]}]}